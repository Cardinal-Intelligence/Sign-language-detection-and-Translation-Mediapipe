{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bbedb7-f817-4fb1-b1ed-a92c4fde40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2eebd-d208-4cd4-97ff-4a96915b8475",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5e7b12-f0e8-4195-ad81-b2957703abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462be278-2c03-4bb7-aa67-b28ac9f22117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f45abb-d088-4229-83ba-a5068ee12a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks_B(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b3697-ff3e-41e1-9b38-4dedcf6bed4f",
   "metadata": {},
   "source": [
    "## Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20da807-b757-494d-acf0-063246071697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', 150)\n",
    "\n",
    "    #Setting the voice\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "    #Text input\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2ee3b-78eb-45e1-afbe-b3352d017ed1",
   "metadata": {},
   "source": [
    "# Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94cf1649-4292-4cd8-977f-1bdc3fef8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('MP_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7faf98a2-fa73-4494-bbd5-f681d94103e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n",
      "P 0.34739850740091816\n"
     ]
    }
   ],
   "source": [
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.8\n",
    "#minimum number of predictions for confirmation\n",
    "pr = 3\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks_B(image, results)\n",
    "        \n",
    "        #Export Cordinates\n",
    "        try:\n",
    "             #Extract hand and face  landmarks\n",
    "            lh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3))\n",
    "            rh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3))\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3))\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3))\n",
    "            \n",
    "            #Concatenate rows\n",
    "            row = lh_row + rh_row + face_row + pose_row\n",
    "            \n",
    "            #Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            sign_class = model.predict(X)[0]\n",
    "            sign_prob = model.predict_proba(X)[0]\n",
    "                        \n",
    "            #Sentence Logic\n",
    "            if sign_prob[np.argmax(sign_prob)] > threshold:\n",
    "                predictions.append(sign_class)\n",
    "                print(sign_class, sign_prob[np.argmax(sign_prob)])\n",
    "                if predictions[-pr:] == [sign_class]*pr:\n",
    "                    if len(sentence) > 0:\n",
    "                        if sign_class != sentence[-1]:\n",
    "                            sentence.append(sign_class)\n",
    "                            speak(sign_class)\n",
    "                    else:\n",
    "                        sentence.append(sign_class)\n",
    "                        speak(sign_class)\n",
    "                    \n",
    "            \n",
    "            if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]\n",
    "            \n",
    "            cv2.rectangle(image, (0,0), (640,40),(0,0,0), -1 )\n",
    "            cv2.putText(image,  ' '.join(sentence), (3,30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31be636-57fb-439f-970a-2e3fef35f000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBMAI2",
   "language": "python",
   "name": "ibmai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
