{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9c5dca",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043da368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0febc5",
   "metadata": {},
   "source": [
    "# Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b750ce",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f22093",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7097472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ce76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb3c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 1,circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 1,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 3,circle_radius=3)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9a6cd9-8e4d-49be-a638-8e35570b0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks_np(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 1,circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 1,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee508f9",
   "metadata": {},
   "source": [
    "### Detecting from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd112427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter picture input/ file path\n",
    "rawpic = os.path.join(\"Guardian Demon 18.png\")\n",
    "\n",
    "#convert to a numpy array\n",
    "pic = cv2.imread(rawpic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed2c1f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-25bd487a759a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#make detections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpicpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholistic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#draw landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-73888fbd0fdd>\u001b[0m in \u001b[0;36mmediapipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #make detections\n",
    "    picpr, results = mediapipe_detection(pic, holistic)\n",
    "    \n",
    "    #draw landmarks\n",
    "    #draw_landmarks(image, results)\n",
    "    draw_styled_landmarks(picpr, results)\n",
    "    \n",
    "    #display image\n",
    "    plt.imshow(cv2.cvtColor(picpr, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e7d0f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save output as jpeg\n",
    "cv2.imwrite(\"out.jpg\", picpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9b63d",
   "metadata": {},
   "source": [
    "### Detecting from Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc0bad-59bc-4478-a588-e03088e547e7",
   "metadata": {},
   "source": [
    "#### Overlayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998ac66-e297-42c2-a50f-cda77e712165",
   "metadata": {},
   "source": [
    "##### laptop webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0f71490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b24dd1-daae-408b-aa8a-68a7009dac12",
   "metadata": {},
   "source": [
    "##### IP webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07131198-5f6a-4fc5-b5e0-3c0dc1ecf608",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"http://192.168.1.36:8080/video\")\n",
    "\n",
    "#Resizing feed\n",
    "scale_percent = 40 # percent of original size\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        #Resizing\n",
    "        #resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "        resized = cv2.resize(image, dim)\n",
    "        \n",
    "        #Flipping\n",
    "        im_flip = cv2.rotate(resized,0)\n",
    "        \n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', im_flip)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3b6c1-a949-4d52-acef-5ea656c38e9f",
   "metadata": {},
   "source": [
    "#### Black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a3f1a9-130e-4434-8583-84b42131eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First large number is the number of pixels in the columns or width\n",
    "frame1 = np.full((640,3),0)\n",
    "# the *160 is the number of pixels in the rows/ height divided by 3\n",
    "frame2 = np.array([frame1,frame1,frame1]*160,dtype=np.uint8)\n",
    "\n",
    "cap = cv2.VideoCapture(\"http://192.168.43.52:8080/video\")\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #style stuff, change frame2 to image from draw landmarks below for overlayed output\n",
    "        frame2 = np.array([frame1,frame1,frame1]*160,dtype=np.uint8)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(frame2, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', frame2)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0d325",
   "metadata": {},
   "source": [
    "### Detecting from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8c5425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter video input/ file path\n",
    "video = \"signtest.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7eb1c-4506-4e3c-9908-147436f5d17b",
   "metadata": {},
   "source": [
    "#### Overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e3d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    #Establish capture\n",
    "    cap = cv2.VideoCapture(os.path.join(video))\n",
    "    \n",
    "    #Setup Video writer\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    #Videowriter\n",
    "    video_writer = cv2.VideoWriter(os.path.join('output3.mp4'), cv2.VideoWriter_fourcc('M','P','4','2'), fps, (width, height))\n",
    "    \n",
    "    # Loop through each frame\n",
    "    for frame_idx in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #Write out frame\n",
    "        #video_writer.write(image)\n",
    "\n",
    "        #Breaking the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    #close down everything\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b70d2c-11f2-4af4-9f1b-04fabb0329bf",
   "metadata": {},
   "source": [
    "#### Black Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feba89d8-1645-422e-9358-2dc3ec7230d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    #Establish capture\n",
    "    cap = cv2.VideoCapture(os.path.join(video))\n",
    "    \n",
    "    #Setup Video writer\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    frame1 = np.full((width,3),0)\n",
    "        \n",
    "    #Videowriter\n",
    "    video_writer = cv2.VideoWriter(os.path.join('signttestOutput.mp4'), cv2.VideoWriter_fourcc('P','I','M','1'), fps, (width, height))\n",
    "    \n",
    "    # Loop through each frame\n",
    "    for frame_idx in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        frame2 = np.array([frame1,frame1,frame1]*int(height/3),dtype=np.uint8)\n",
    "\n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(frame2, results)\n",
    "        #draw_styled_landmarks_np(frame2, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', frame2)\n",
    "        \n",
    "        #Write out frame\n",
    "        #video_writer.write(frame2)\n",
    "\n",
    "        #Breaking the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    #close down everything\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb08556",
   "metadata": {},
   "source": [
    "## Extracting keypoint values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60848ca-c0fa-4e40-9247-8fe777b0b222",
   "metadata": {},
   "source": [
    "### Creating CSV file to collect landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdd0ca83-64e1-42d7-b7a6-804bc17713f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c423194-1536-4441-b580-b97f79b58284",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_f = np.zeros(468)\n",
    "hand_f = np.zeros(21)\n",
    "pose_f = np.zeros(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "851b056c-9e38-4b4c-af86-3c6922659811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(hand_f*2) + len(face_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72864500-8435-4158-8fc8-086a08d8de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks +=['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef21f05e-9a29-46a7-ad63-bbdd0efc19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad061e-a04b-41a0-aba6-b47ba3a80153",
   "metadata": {},
   "source": [
    "### Defining class to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28ec3bc0-8e06-4991-a1fb-9a1cea34d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter new classification class\n",
    "class_name = \"Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72518658-c21c-4be6-8598-23ffa0cf64a9",
   "metadata": {},
   "source": [
    "### Keypoint collection from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4458214d-155f-45c8-8944-11bc572d2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks_np(image, results)\n",
    "        \n",
    "        #Export Cordinates\n",
    "        try:\n",
    "            #Extract hand and face  landmarks\n",
    "            lh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3))\n",
    "            rh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3))\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3))\n",
    "            \n",
    "            #Concatenate rows\n",
    "            row = lh_row + rh_row + face_row\n",
    "            \n",
    "            #Append Class Name\n",
    "            row.insert(0,class_name)\n",
    "            \n",
    "            #Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfcd78-bcc5-45f1-8137-6afd2f9304fd",
   "metadata": {},
   "source": [
    "## Train Custom model with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83655f09-852d-4dde-bfd8-34c3ea9b84a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARKMA~1\\AppData\\Local\\Temp/ipykernel_292/1801383384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "137093d8-abef-4a1c-9f39-8ca3a29cd9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp39-cp39-win_amd64.whl (10.5 MB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.1 pytz-2021.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c0480-2305-4cda-b388-311dc5dd2974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBMAI2",
   "language": "python",
   "name": "ibmai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
