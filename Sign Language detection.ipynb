{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9c5dca",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e8485a-6e06-4606-b529-1f2cbfff32cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.62-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.62\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (4.5.5.62)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install mediapipe\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3136aca6-343d-4b81-be5d-299f91c2b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4613a9c-d0c9-48e6-b2af-0a9f13e6d9a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\playground\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=07455df48a685079fbf37daef0ff2685b8fcd700eaca555c9d5f8bf51b2a2266\n",
      "  Stored in directory: c:\\users\\mark maara\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043da368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0febc5",
   "metadata": {},
   "source": [
    "# Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b750ce",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f22093",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7097472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ce76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb3c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 1,circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 1,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 3,circle_radius=3)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9a6cd9-8e4d-49be-a638-8e35570b0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks_np(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 1,circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 1,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(43,180,255), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee508f9",
   "metadata": {},
   "source": [
    "### Detecting from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd112427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter picture input/ file path\n",
    "rawpic = os.path.join(\"Guardian Demon 18.png\")\n",
    "\n",
    "#convert to a numpy array\n",
    "pic = cv2.imread(rawpic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed2c1f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-25bd487a759a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#make detections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpicpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholistic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#draw landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-73888fbd0fdd>\u001b[0m in \u001b[0;36mmediapipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #make detections\n",
    "    picpr, results = mediapipe_detection(pic, holistic)\n",
    "    \n",
    "    #draw landmarks\n",
    "    #draw_landmarks(image, results)\n",
    "    draw_styled_landmarks(picpr, results)\n",
    "    \n",
    "    #display image\n",
    "    plt.imshow(cv2.cvtColor(picpr, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e7d0f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save output as jpeg\n",
    "cv2.imwrite(\"out.jpg\", picpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9b63d",
   "metadata": {},
   "source": [
    "### Detecting from Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc0bad-59bc-4478-a588-e03088e547e7",
   "metadata": {},
   "source": [
    "#### Overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f71490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3b6c1-a949-4d52-acef-5ea656c38e9f",
   "metadata": {},
   "source": [
    "#### Black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a3f1a9-130e-4434-8583-84b42131eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First large number is the number of pixels in the columns or width\n",
    "frame1 = np.full((640,3),0)\n",
    "# the *160 is the number of pixels in the rows/ height divided by 3\n",
    "frame2 = np.array([frame1,frame1,frame1]*160,dtype=np.uint8)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #style stuff, change frame2 to image from draw landmarks below for overlayed output\n",
    "        frame2 = np.array([frame1,frame1,frame1]*160,dtype=np.uint8)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(frame2, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', frame2)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0d325",
   "metadata": {},
   "source": [
    "### Detecting from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c5425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter video input/ file path\n",
    "video = \"signtest.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7eb1c-4506-4e3c-9908-147436f5d17b",
   "metadata": {},
   "source": [
    "#### Overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e3d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    #Establish capture\n",
    "    cap = cv2.VideoCapture(os.path.join(video))\n",
    "    \n",
    "    #Setup Video writer\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    #Videowriter\n",
    "    video_writer = cv2.VideoWriter(os.path.join('output3.mp4'), cv2.VideoWriter_fourcc('M','P','4','2'), fps, (width, height))\n",
    "    \n",
    "    # Loop through each frame\n",
    "    for frame_idx in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #Write out frame\n",
    "        #video_writer.write(image)\n",
    "\n",
    "        #Breaking the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    #close down everything\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b70d2c-11f2-4af4-9f1b-04fabb0329bf",
   "metadata": {},
   "source": [
    "#### Black Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feba89d8-1645-422e-9358-2dc3ec7230d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    #Establish capture\n",
    "    cap = cv2.VideoCapture(os.path.join(video))\n",
    "    \n",
    "    #Setup Video writer\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    frame1 = np.full((width,3),0)\n",
    "        \n",
    "    #Videowriter\n",
    "    video_writer = cv2.VideoWriter(os.path.join('signttestOutput.mp4'), cv2.VideoWriter_fourcc('P','I','M','1'), fps, (width, height))\n",
    "    \n",
    "    # Loop through each frame\n",
    "    for frame_idx in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        frame2 = np.array([frame1,frame1,frame1]*int(height/3),dtype=np.uint8)\n",
    "\n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(frame2, results)\n",
    "        #draw_styled_landmarks_np(frame2, results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', frame2)\n",
    "        \n",
    "        #Write out frame\n",
    "        #video_writer.write(frame2)\n",
    "\n",
    "        #Breaking the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    #close down everything\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb08556",
   "metadata": {},
   "source": [
    "## Extracting keypoint values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c881e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh =np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b288d",
   "metadata": {},
   "source": [
    "## Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a568f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_DATA')\n",
    "\n",
    "#Actions that we are trying to deetect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "\n",
    "#Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "#videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4048c",
   "metadata": {},
   "source": [
    "## Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68269ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-493154a4e60b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;31m#make detections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholistic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m#draw landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-73888fbd0fdd>\u001b[0m in \u001b[0;36mmediapipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \"\"\"\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    332\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m# output stream names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #loop through actions\n",
    "    for action in actions:\n",
    "        #loop through videos\n",
    "        for sequence in range(no_sequences):\n",
    "            #loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "                \n",
    "                #read frame\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                #make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                #draw landmarks\n",
    "                #draw_landmarks(image, results)\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                #apply wait logic\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image,'STARTING COLLECTION',(120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4,cv2.LINE_AA)\n",
    "                    cv2.putText(image,'Collecting frames for {} Video Number{}'.format(action, sequence),(15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1,cv2.LINE_AA)\n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(image,'Collecting frames for {} Video Number{}'.format(action, sequence),(15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1,cv2.LINE_AA)\n",
    "                    \n",
    "                #Emport keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence),str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                #show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                #break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c2eb21-bf83-4340-9e59-ae48985612fa",
   "metadata": {},
   "source": [
    "## Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414caff0-514a-4052-9723-dfabd0da21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb83319f-dc50-445e-a69c-cff67278458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9a8dc6-f020-4b94-900c-fa9e5ed3e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action,str(sequence),\"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55402c09-919e-42b6-b31d-4909101b0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4022754-be7a-45cc-a18d-46ffc3404ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb489258-2f1d-4c47-81d0-015cab3efe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf88812-eccf-4cf7-aabe-6f8231b19ce6",
   "metadata": {},
   "source": [
    "## Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceabf16c-009e-48a4-9cba-b6bb21d44c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ffd6495-c2c9-4c22-8997-fa3341881068",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs')\n",
    "tb_callback = TensorBoard(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4df636cc-228b-4287-bfa6-3dcfd7993580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "802d58ea-fedd-49d6-93d0-7a6d115af3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "253a6daa-e1a6-461e-81bc-7010fac0efae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.3244 - categorical_accuracy: 0.8824\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3585 - categorical_accuracy: 0.9059\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3677 - categorical_accuracy: 0.8353\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2817 - categorical_accuracy: 0.8941\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.3195 - categorical_accuracy: 0.9059\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2528 - categorical_accuracy: 0.9176\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2423 - categorical_accuracy: 0.9176\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.2436 - categorical_accuracy: 0.9059\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.2189 - categorical_accuracy: 0.9412\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.2372 - categorical_accuracy: 0.9176\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2043 - categorical_accuracy: 0.9529\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2033 - categorical_accuracy: 0.9412\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1852 - categorical_accuracy: 0.9412\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2146 - categorical_accuracy: 0.9412\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2101 - categorical_accuracy: 0.9176\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2338 - categorical_accuracy: 0.8824\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2288 - categorical_accuracy: 0.9294\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2293 - categorical_accuracy: 0.9294\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2031 - categorical_accuracy: 0.9529\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3190 - categorical_accuracy: 0.8824\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3401 - categorical_accuracy: 0.8588\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.3996 - categorical_accuracy: 0.8706\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.5446 - categorical_accuracy: 0.8000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.4146 - categorical_accuracy: 0.8588\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.3146 - categorical_accuracy: 0.9176\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2692 - categorical_accuracy: 0.8824\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2235 - categorical_accuracy: 0.9176\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.2577 - categorical_accuracy: 0.9059\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2388 - categorical_accuracy: 0.9059\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2166 - categorical_accuracy: 0.9176\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.2051 - categorical_accuracy: 0.9412\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.2228 - categorical_accuracy: 0.9176\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.1925 - categorical_accuracy: 0.9176\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2135 - categorical_accuracy: 0.9294\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 181ms/step - loss: 0.2264 - categorical_accuracy: 0.9294\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2662 - categorical_accuracy: 0.8706\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.2294 - categorical_accuracy: 0.9059\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2022 - categorical_accuracy: 0.8941\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.2159 - categorical_accuracy: 0.9294\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1615 - categorical_accuracy: 0.9529\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.3148 - categorical_accuracy: 0.8824\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2201 - categorical_accuracy: 0.9294\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 186ms/step - loss: 0.2142 - categorical_accuracy: 0.9176\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2103 - categorical_accuracy: 0.9294\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1481 - categorical_accuracy: 0.9529\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.1588 - categorical_accuracy: 0.9412\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1869 - categorical_accuracy: 0.9294\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1290 - categorical_accuracy: 0.9529\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1446 - categorical_accuracy: 0.9412\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1452 - categorical_accuracy: 0.9412\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1316 - categorical_accuracy: 0.9412\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1177 - categorical_accuracy: 0.9765\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1052 - categorical_accuracy: 0.9765\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1608 - categorical_accuracy: 0.9294\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2352 - categorical_accuracy: 0.9176\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.6479 - categorical_accuracy: 0.7882\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 1.3811 - categorical_accuracy: 0.5647\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.4318 - categorical_accuracy: 0.8118\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.4116 - categorical_accuracy: 0.8824\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.5633 - categorical_accuracy: 0.8118\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3976 - categorical_accuracy: 0.8941\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3468 - categorical_accuracy: 0.8824\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 0.4088 - categorical_accuracy: 0.8706\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3284 - categorical_accuracy: 0.8824\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.4018 - categorical_accuracy: 0.8941\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3265 - categorical_accuracy: 0.8941\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3457 - categorical_accuracy: 0.8824\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3209 - categorical_accuracy: 0.8824\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.3089 - categorical_accuracy: 0.9059\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3040 - categorical_accuracy: 0.8941\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.2849 - categorical_accuracy: 0.8941\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2683 - categorical_accuracy: 0.8824\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.2792 - categorical_accuracy: 0.8941\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2671 - categorical_accuracy: 0.9059\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 0.2882 - categorical_accuracy: 0.8941\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 0.2565 - categorical_accuracy: 0.8941\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2791 - categorical_accuracy: 0.8941\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2403 - categorical_accuracy: 0.9176\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2631 - categorical_accuracy: 0.9059\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2246 - categorical_accuracy: 0.9176\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2228 - categorical_accuracy: 0.9059\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2115 - categorical_accuracy: 0.9412\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2252 - categorical_accuracy: 0.9176\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.1963 - categorical_accuracy: 0.9412\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2011 - categorical_accuracy: 0.9176\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1912 - categorical_accuracy: 0.9059\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 191ms/step - loss: 0.1738 - categorical_accuracy: 0.9529\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1688 - categorical_accuracy: 0.9529\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1564 - categorical_accuracy: 0.9765\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 1s 267ms/step - loss: 0.1548 - categorical_accuracy: 0.9529\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1585 - categorical_accuracy: 0.9765\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1817 - categorical_accuracy: 0.9412\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.1677 - categorical_accuracy: 0.9412\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.1878 - categorical_accuracy: 0.9412\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1558 - categorical_accuracy: 0.9412\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1380 - categorical_accuracy: 0.9647\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1387 - categorical_accuracy: 0.9529\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1184 - categorical_accuracy: 0.9765\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1215 - categorical_accuracy: 0.9647\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1183 - categorical_accuracy: 0.9765\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.1035 - categorical_accuracy: 0.9882\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1090 - categorical_accuracy: 0.9765\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.1061 - categorical_accuracy: 0.9765\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0996 - categorical_accuracy: 0.9765\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1181 - categorical_accuracy: 0.9647\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1642 - categorical_accuracy: 0.9412\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1450 - categorical_accuracy: 0.9412\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2479 - categorical_accuracy: 0.9059\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1589 - categorical_accuracy: 0.9412\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0907 - categorical_accuracy: 0.9882\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1493 - categorical_accuracy: 0.9294\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1648 - categorical_accuracy: 0.9529\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.1570 - categorical_accuracy: 0.9529\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1371 - categorical_accuracy: 0.9529\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1306 - categorical_accuracy: 0.9529\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1128 - categorical_accuracy: 0.9647\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0816 - categorical_accuracy: 0.9882\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1067 - categorical_accuracy: 0.9647\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.1051 - categorical_accuracy: 0.9765\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.1007 - categorical_accuracy: 0.9647\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.1129 - categorical_accuracy: 0.9647\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1336 - categorical_accuracy: 0.9529\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2160 - categorical_accuracy: 0.9294\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.4587 - categorical_accuracy: 0.8471\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.3726 - categorical_accuracy: 0.8824\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2959 - categorical_accuracy: 0.9059\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1483 - categorical_accuracy: 0.9647\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1207 - categorical_accuracy: 0.9882\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.1819 - categorical_accuracy: 0.9294\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1779 - categorical_accuracy: 0.9059\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1741 - categorical_accuracy: 0.9412\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1659 - categorical_accuracy: 0.9176\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1294 - categorical_accuracy: 0.9765\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.1507 - categorical_accuracy: 0.9412\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0968 - categorical_accuracy: 0.9882\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0936 - categorical_accuracy: 0.9765\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0965 - categorical_accuracy: 0.9765\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0853 - categorical_accuracy: 0.9882\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0868 - categorical_accuracy: 0.9765\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0798 - categorical_accuracy: 0.9882\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0847 - categorical_accuracy: 0.9765\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0823 - categorical_accuracy: 0.9765\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0760 - categorical_accuracy: 0.9882\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0744 - categorical_accuracy: 0.9882\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0709 - categorical_accuracy: 0.9882\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0856 - categorical_accuracy: 0.9765\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1249 - categorical_accuracy: 0.9412\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2579 - categorical_accuracy: 0.9059\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.5866 - categorical_accuracy: 0.8353\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 1.1622 - categorical_accuracy: 0.6824\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 1.1949 - categorical_accuracy: 0.5765\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.9551 - categorical_accuracy: 0.4588\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.6835 - categorical_accuracy: 0.4824\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.5603 - categorical_accuracy: 0.7765\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.5402 - categorical_accuracy: 0.6471\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.5065 - categorical_accuracy: 0.6824\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4186 - categorical_accuracy: 0.9059\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3385 - categorical_accuracy: 0.8824\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2962 - categorical_accuracy: 0.9412\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2768 - categorical_accuracy: 0.9529\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2499 - categorical_accuracy: 0.9412\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.2270 - categorical_accuracy: 0.9176\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1804 - categorical_accuracy: 0.9529\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1762 - categorical_accuracy: 0.9412\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1591 - categorical_accuracy: 0.9647\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1299 - categorical_accuracy: 0.9647\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.1280 - categorical_accuracy: 0.9529\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.1158 - categorical_accuracy: 0.9647\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1591 - categorical_accuracy: 0.9412\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1642 - categorical_accuracy: 0.9294\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1613 - categorical_accuracy: 0.9412\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1072 - categorical_accuracy: 0.9647\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1113 - categorical_accuracy: 0.9647\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.1021 - categorical_accuracy: 0.9647\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0982 - categorical_accuracy: 0.9647\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0980 - categorical_accuracy: 0.9647\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0800 - categorical_accuracy: 0.9882\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1013 - categorical_accuracy: 0.9647\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0862 - categorical_accuracy: 0.9765\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0767 - categorical_accuracy: 0.9882\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0795 - categorical_accuracy: 0.9765\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0873 - categorical_accuracy: 0.9529\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0658 - categorical_accuracy: 0.9882\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1141 - categorical_accuracy: 0.9647\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1288 - categorical_accuracy: 0.9412\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1448 - categorical_accuracy: 0.9529\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0997 - categorical_accuracy: 0.9765\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3017 - categorical_accuracy: 0.8941\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2980 - categorical_accuracy: 0.8824\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3253 - categorical_accuracy: 0.8824\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2103 - categorical_accuracy: 0.9412\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2727 - categorical_accuracy: 0.8471\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3977 - categorical_accuracy: 0.8000\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.1957 - categorical_accuracy: 0.9412\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3039 - categorical_accuracy: 0.8471\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1725 - categorical_accuracy: 0.9412\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1993 - categorical_accuracy: 0.9294\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1410 - categorical_accuracy: 0.9765\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1873 - categorical_accuracy: 0.9412\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1205 - categorical_accuracy: 0.9647\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1384 - categorical_accuracy: 0.9529\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1119 - categorical_accuracy: 0.9765\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1093 - categorical_accuracy: 0.9647\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0958 - categorical_accuracy: 0.9765\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0975 - categorical_accuracy: 0.9765\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0981 - categorical_accuracy: 0.9647\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0730 - categorical_accuracy: 0.9882\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0970 - categorical_accuracy: 0.9647\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0741 - categorical_accuracy: 0.9882\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0904 - categorical_accuracy: 0.9765\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0691 - categorical_accuracy: 0.9765\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0673 - categorical_accuracy: 0.9882\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.0627 - categorical_accuracy: 0.9882\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0646 - categorical_accuracy: 0.9765\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0620 - categorical_accuracy: 0.9882\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0622 - categorical_accuracy: 0.9882\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0589 - categorical_accuracy: 0.9882\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0568 - categorical_accuracy: 0.9882\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0570 - categorical_accuracy: 0.9882\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0540 - categorical_accuracy: 0.9882\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0582 - categorical_accuracy: 0.9882\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0607 - categorical_accuracy: 0.9882\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0625 - categorical_accuracy: 0.9882\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0569 - categorical_accuracy: 0.9882\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0546 - categorical_accuracy: 0.9882\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0513 - categorical_accuracy: 0.9882\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0561 - categorical_accuracy: 0.9882\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0523 - categorical_accuracy: 0.9882\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0515 - categorical_accuracy: 0.9882\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 0.0589 - categorical_accuracy: 0.9882\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0685 - categorical_accuracy: 0.9765\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0609 - categorical_accuracy: 0.9882\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0527 - categorical_accuracy: 0.9882\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0626 - categorical_accuracy: 0.9765\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0658 - categorical_accuracy: 0.9765\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0690 - categorical_accuracy: 0.9765\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0481 - categorical_accuracy: 0.9882\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0622 - categorical_accuracy: 0.9882\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.0506 - categorical_accuracy: 0.9882\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0487 - categorical_accuracy: 0.9882\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0531 - categorical_accuracy: 0.9882\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 0.0480 - categorical_accuracy: 0.9882\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0502 - categorical_accuracy: 0.9882\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0463 - categorical_accuracy: 0.9882\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0477 - categorical_accuracy: 0.9882\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 181ms/step - loss: 0.0467 - categorical_accuracy: 0.9882\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0506 - categorical_accuracy: 0.9882\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0473 - categorical_accuracy: 0.9882\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0449 - categorical_accuracy: 0.9882\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0469 - categorical_accuracy: 0.9882\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0458 - categorical_accuracy: 0.9882\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0465 - categorical_accuracy: 0.9882\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0450 - categorical_accuracy: 0.9882\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.0448 - categorical_accuracy: 0.9882\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0442 - categorical_accuracy: 0.9882\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0448 - categorical_accuracy: 0.9882\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0442 - categorical_accuracy: 0.9882\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0440 - categorical_accuracy: 0.9882\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0441 - categorical_accuracy: 0.9882\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0447 - categorical_accuracy: 0.9882\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 193ms/step - loss: 0.0435 - categorical_accuracy: 0.9882\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0453 - categorical_accuracy: 0.9882\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0444 - categorical_accuracy: 0.9882\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0450 - categorical_accuracy: 0.9882\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0431 - categorical_accuracy: 0.9882\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0456 - categorical_accuracy: 0.9882\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0427 - categorical_accuracy: 0.9882\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0452 - categorical_accuracy: 0.9882\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0458 - categorical_accuracy: 0.9882\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0433 - categorical_accuracy: 0.9882\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0427 - categorical_accuracy: 0.9882\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0432 - categorical_accuracy: 0.9882\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0434 - categorical_accuracy: 0.9882\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0439 - categorical_accuracy: 0.9882\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0429 - categorical_accuracy: 0.9882\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 0.0426 - categorical_accuracy: 0.9882\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0418 - categorical_accuracy: 0.9882\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0428 - categorical_accuracy: 0.9882\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0419 - categorical_accuracy: 0.9882\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0422 - categorical_accuracy: 0.9882\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0422 - categorical_accuracy: 0.9882\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0414 - categorical_accuracy: 0.9882\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0416 - categorical_accuracy: 0.9882\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0413 - categorical_accuracy: 0.9882\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0407 - categorical_accuracy: 0.9882\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0418 - categorical_accuracy: 0.9882\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0418 - categorical_accuracy: 0.9882\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0411 - categorical_accuracy: 0.9882\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0420 - categorical_accuracy: 0.9882\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0415 - categorical_accuracy: 0.9882\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 180ms/step - loss: 0.0399 - categorical_accuracy: 0.9882\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0420 - categorical_accuracy: 0.9882\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0400 - categorical_accuracy: 0.9882\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 190ms/step - loss: 0.0401 - categorical_accuracy: 0.9882\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0413 - categorical_accuracy: 0.9882\n",
      "Epoch 302/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0499 - categorical_accuracy: 0.9844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-dbe7249bd7f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IBMAI\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 500, callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceb54e7e-8050-4c6c-8ea2-683fd68c21f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9515d-417d-4fa3-9d4e-95029f8f74d7",
   "metadata": {},
   "source": [
    "## Make predictons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea214b7-d25c-458b-9747-61095fe93eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "548b9140-dd21-4f33-9416-391198d50aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222cf4d7-90fc-479b-b2c1-d08c1cd138ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee68ae-8fb4-4a09-be35-985f9f5eab0f",
   "metadata": {},
   "source": [
    "## Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4a1cd2f-59c8-49c5-8605-35811dc2b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0fc1567-5596-47c4-a32d-d391b72c8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "920a19e5-048c-408b-95e3-ff1dc33a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2df3a-53a7-4054-8593-c6e154c4dc71",
   "metadata": {},
   "source": [
    "## Evaluation using confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c1811f0-c4cc-4eed-af03-c2586bbac8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b377781-dfba-4b69-bb92-a43669a91797",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a078832-3f0f-4071-9b00-be82ce3fb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat =np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4ba7de2-daf5-4add-9a8a-f8c3983f2457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 3]]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e1fead3-ed26-4f30-a459-78fa13169571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d8379-20ac-4e12-9cd3-baad34fa4e5e",
   "metadata": {},
   "source": [
    "## Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec692872-7a2e-4d6c-92f4-77770523d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16),(117,245,16),(16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100),90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0,85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33cfbdee-1f3f-470a-93fb-560a1d35c834",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "iloveyou\n"
     ]
    }
   ],
   "source": [
    "#New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        #Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "        #visualisation logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    if len(sentence)>0:\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "\n",
    "                if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]\n",
    "                \n",
    "                #Visualise probalilties\n",
    "                image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640,40),(245,117,16), -1 )\n",
    "        cv2.putText(image,  ' '.join(sentence), (3,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ecb12-6592-47b5-bd21-403295e01dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBMAI2",
   "language": "python",
   "name": "ibmai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
